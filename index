app = customtkinter.CTk()
app.title("Aliexpress Crawler")
app.geometry("600x400")

def get_des(url):
    html = requests.get(url).text
    soup = bs4.BeautifulSoup(html, 'html.parser')
    p_tags = soup.find_all('p')
    p_texts = ''.join([unicodedata.normalize("NFKD", tag.get_text()) for tag in p_tags])
    img_tags = soup.find_all('img')
    img_srcs = [tag.get('src') for tag in img_tags]
    return p_texts, img_srcs

def extract_between(text, sub1, sub2):
    return [t.split(sub2)[0] for t in text.split(sub1)[1:]]

logging.getLogger('seleniumwire').setLevel(logging.CRITICAL)
logging.getLogger('selenium').setLevel(logging.CRITICAL)

response = requests.get(
    "https://proxy.webshare.io/api/v2/proxy/list/?mode=direct&page=1&page_size=25",
    headers={"Authorization": "Token wcc6luoipd5ja0z0hvgex5p2c0agb8uw8vh8d82c"}
    ).json()
proxy_list = response['results']

def get_random_proxy():
    global proxy_list
    p = random.choice(proxy_list)
    return f'{p["username"]}:{p["password"]}@{p["proxy_address"]}:{p["port"]}'

def get_detail(url):

    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument('--log-level=3')
    chrome_options.add_argument('--disable-logging')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--no-sandbox')
    p = get_random_proxy()
    log_frame.configure(state="normal")
    log_frame.insert("end", f"Set ip: {p.split("@")[1].split(":")[0]}\n")
    log_frame.configure(state="disabled")
    options = {
        'proxy': {
            'http': f'http://{p}',
            'https': f'http://{p}',
            'no_proxy': 'localhost,127.0.0.1'
        }
    }

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options, seleniumwire_options=options)
    driver.get(url)
    for request in driver.requests:
        if "/h5/mtop.aliexpress.pdp.pc.query/1.0/" in request.url:
            if request.response:
                response_body = request.response.body
                if request.response.headers.get('Content-Encoding') == 'gzip':
                    buf = BytesIO(response_body)
                    f = gzip.GzipFile(fileobj=buf)
                    response_body = f.read().decode('utf-8')
                else:
                    response_body = response_body.decode('utf-8')
                if '"ret":["SUCCESS' in response_body:
                    os.system("taskkill /f /im chrome.exe")
                    os.system("taskkill /f /im chromedriver.exe")

                    driver.quit()
                    return response_body
    
    os.system("taskkill /f /im chrome.exe")
    os.system("taskkill /f /im chromedriver.exe")
    driver.quit()
    return None

def crawl_product(url):
    global list_ck, file_path_result, font
    wb = openpyxl.load_workbook(file_path_result)
    ws = wb.active
    try:
        while True:
            detail = get_detail(url)
            if detail is not None:
                break
        while True:
            try:
                des = get_des(detail.split('pcDescUrl":"')[1].split('"')[0])[0]
                name = detail.split('"subject":"')[1].split('"')[0]
                break
            except Exception as e:
                pass
        next_row = ws.max_row + 1
        ws['A' + str(next_row)] = prefix_input.get()
        ws['A' + str(next_row)].font = font
        ws['B' + str(next_row)] = prefix_input.get()
        ws['B' + str(next_row)].font = font
        ws['C' + str(next_row)] = prefix_input.get()
        ws['C' + str(next_row)].font = font
        ws['D' + str(next_row)] = prefix_input.get()
        ws['D' + str(next_row)].font = font
        ws['J' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"
        ws['J' + str(next_row)].font = font
        ws['M' + str(next_row)] = 50
        ws['M' + str(next_row)].font = font
        ws['U' + str(next_row)] = "Parent"
        ws['U' + str(next_row)].font = font
        ws['X' + str(next_row)] = "Color"
        ws['X' + str(next_row)].font = font
        ws['H' + str(next_row)] = url
        ws['H' + str(next_row)].font = font
        ws['K' + str(next_row)] = name
        ws['K' + str(next_row)].font = font
        ws['AA' + str(next_row)] = des
        ws['AA' + str(next_row)].font = font
        ws['AJ' + str(next_row)] = "1"
        ws['AJ' + str(next_row)].font = font
        ws['AK' + str(next_row)] = "Count"
        ws['AK' + str(next_row)].font = font
        ws['AN' + str(next_row)] = "10"
        ws['AN' + str(next_row)].font = font
        wb.save(file_path_result)

        def extract_last_before_sub2(text, sub1, sub2):
            return text.split(sub2)[0].split(sub1)[-1]
        print(detail.count('"skuPropertyValues":'))
        if detail.count('"skuPropertyValues":')==0:
            next_row = ws.max_row + 1
            ws['A' + str(next_row)] = prefix_input.get()
            ws['B' + str(next_row)] = prefix_input.get()
            ws['C' + str(next_row)] = prefix_input.get()
            ws['D' + str(next_row)] = prefix_input.get()
            ws['K' + str(next_row)] = name
            ws['AA' + str(next_row)] = des
            ws['H' + str(next_row)] = url
            ws['M' + str(next_row)] = 50
            ws['U' + str(next_row)] = "Child"
            ws['W' + str(next_row)] = "Variation"
            ws['X' + str(next_row)] = "Color"
            ws['AJ' + str(next_row)] = "1"
            ws['AK' + str(next_row)] = "Count"
            ws['AN' + str(next_row)] = "10"
            ws['J' + str(next_row)] = f"{prefix_input.get()}-1-{url.split('/')[-1].split('.html')[0]}"
            ws['V' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"
            a = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            ws['N' + str(next_row)] = a[0]
            img_url_index = 0
            for j in ["O", "P", "Q", "R", "S", "T"]:
                try:
                    ws[j + str(next_row)] = a[img_url_index]
                    img_url_index += 1
                except: break
            price = "9.99"
            ws['L' + str(next_row)] = str(price)
            ws['AI' + str(next_row)] = f"Color - 1"
            ws['AH' + str(next_row)] = f"Color - 1"
            wb.save(file_path_result)
            return
        elif detail.count('"skuPropertyValues":')==1:
            b = detail.split('"skuPropertyValues":[')[1]
            a = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            colors = extract_between(b,'"propertyValueDisplayName":"', '"')
            list_img = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            url_img = extract_between(b,'"skuPropertyImagePath":"', '"')
            dem_sku = 1
            for color in colors:
                next_row = ws.max_row + 1
                ws['A' + str(next_row)] = prefix_input.get()
                ws['B' + str(next_row)] = prefix_input.get()
                ws['C' + str(next_row)] = prefix_input.get()
                ws['D' + str(next_row)] = prefix_input.get()
                ws['K' + str(next_row)] = name
                ws['AA' + str(next_row)] = des
                ws['H' + str(next_row)] = url
                ws['M' + str(next_row)] = 50
                ws['U' + str(next_row)] = "Child"
                ws['W' + str(next_row)] = "Variation"
                ws['X' + str(next_row)] = "Color"
                ws['AJ' + str(next_row)] = "1"
                ws['AK' + str(next_row)] = "Count"
                ws['AN' + str(next_row)] = "10"
                ws['J' + str(next_row)] = f"{prefix_input.get()}-{dem_sku}-{url.split('/')[-1].split('.html')[0]}"
                ws['V' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"

                img_url_index = 0
                for j in ["O", "P", "Q", "R", "S", "T"]:
                    try:
                        ws[j + str(next_row)] = list_img[img_url_index]
                        img_url_index += 1
                    except: break    
                ws['N' + str(next_row)] = url_img[dem_sku-1]
                price = "9.99"
                ws['L' + str(next_row)] = str(price)
                ws['AI' + str(next_row)] = f"{color} - {dem_sku}"
                ws['AH' + str(next_row)] = f"{color} - {dem_sku}"
                dem_sku += 1
                wb.save(file_path_result)
        elif detail.count('"skuPropertyValues":')==2:
            b = detail.split('"skuPropertyValues":[')[1:]
            a = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            colors = extract_between(b[0],'"propertyValueDisplayName":"', '"')
            sizes = extract_between(b[1],'"propertyValueDisplayName":"', '"')
            url_img = extract_between(b[0],'"skuPropertyImagePath":"', '"')
            list_img = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            for color in colors:
                dem_sku = 1
                for size in sizes:
                    next_row = ws.max_row + 1
                    ws['A' + str(next_row)] = prefix_input.get()
                    ws['B' + str(next_row)] = prefix_input.get()
                    ws['C' + str(next_row)] = prefix_input.get()
                    ws['D' + str(next_row)] = prefix_input.get()
                    ws['K' + str(next_row)] = name
                    ws['AA' + str(next_row)] = des
                    ws['H' + str(next_row)] = url
                    ws['M' + str(next_row)] = 50
                    ws['U' + str(next_row)] = "Child"
                    ws['W' + str(next_row)] = "Variation"
                    ws['X' + str(next_row)] = "Color"
                    ws['AJ' + str(next_row)] = "1"
                    ws['AK' + str(next_row)] = "Count"
                    ws['AN' + str(next_row)] = "10"
                    ws['J' + str(next_row)] = f"{prefix_input.get()}-{dem_sku}-{url.split('/')[-1].split('.html')[0]}"
                    ws['V' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"

                    img_url_index = 0
                    for j in ["O", "P", "Q", "R", "S", "T"]:
                        try:
                            ws[j + str(next_row)] = list_img[img_url_index]
                            img_url_index += 1
                        except: break    
                    ws['N' + str(next_row)] = url_img[dem_sku-1]
                    price = "9.99"
                    ws['L' + str(next_row)] = str(price)
                    ws['AI' + str(next_row)] = f"{color} - {size} - {dem_sku}"
                    ws['AH' + str(next_row)] = f"{color} - {size} - {dem_sku}"
                    dem_sku += 1
                    wb.save(file_path_result)
    except Exception as e:
        def save_error_to_file(error_message):
            with open("error_log.txt", 'a') as f:
                f.write(error_message + '\n')
        tb = e.__traceback__
        error_message = f" {url}| Exception: {e} | "
        while tb is not None:
            filename = tb.tb_frame.f_code.co_filename
            lineno = tb.tb_lineno
            function_name = tb.tb_frame.f_code.co_name
            error_message += f"File: {filename}, Line: {lineno}, in {function_name}\n"
            tb = tb.tb_next
        save_error_to_file(error_message)
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Error: {url}\n")
        log_frame.configure(state="disabled")



def start():
    global file_path_result, font, fill
    file_path_result = f'{prefix_input.get()}-{datetime.datetime.now().strftime("%H-%M-%S-%d-%m-%Y")}.xlsx'
    if not os.path.exists(file_path_result):
        wb = Workbook()
        wb.save(file_path_result)
    wb = openpyxl.load_workbook(file_path_result)
    ws = wb.active
    fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
    font = Font(color="FF0000")
    row_values = [
        ['TemplateType=fptcustom', 'Version=2021.0709', 'TemplateSignature=TVVMVElUT09M', 'settings=contentLanguageTag=en_US&feedType=610841&headerLanguageTag=en_US&primaryMarketplaceId=amzn1.mp.o.ATVPDKIKX0DER&templateIdentifier=c8bf49ba-63dc-4a50-9056-059404a3a2aa&timestamp=2021-07-09T17%3A36%3A18.873Z', 'Use ENGLISH to fill this template.The top 3 rows are for Amazon.com use only. Do not modify or delete the top 3 rows.', 'a1', 'a0', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'Images', 'a9', 'a10', 'a11', 'a12', 'a13', 'Variation', 'a14', 'a15', 'a16', 'Basic', 'a17', 'a18', 'Discovery', 'a19', 'a20', 'a21', 'a22', 'a23', 'a24', 'a25', 'a26', 'a27', 'a28', 'a29', 'a30', 'a31', 'a32', 'a33', 'a34'],
        ['Product Type', 'Item Type Keyword', 'Brand Name', 'Manufacturer', 'Product ID', 'Product ID Type', 'Order Ali', 'Link SP', 'Key Product Features', 'Seller SKU', 'Product Name', 'Standard Price', 'Quantity', 'Main Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Parentage', 'Parent SKU', 'Relationship Type', 'Variation Theme', 'Update Delete', 'Manufacturer Part Number', 'Product Description', 'Catalog Number', 'Key Product Features', 'Key Product Features', 'Key Product Features', 'Key Product Features', 'Search Terms', 'Color', 'Color Map', 'Unit Count', 'Unit Count Type', 'Size', 'Size Map', 'Handling Time', 'Intended Use', 'Target Audience', 'Other Attributes', 'Subject Matter'],
        ['feed_product_type', 'item_type', 'brand_name', 'manufacturer', 'external_product_id', 'external_product_id_type', '', '', 'bullet_point1', 'item_sku', 'item_name', 'standard_price', 'quantity', 'main_image_url', 'other_image_url1', 'other_image_url2', 'other_image_url3', 'other_image_url4', 'other_image_url5', 'other_image_url6', 'parent_child', 'parent_sku', 'relationship_type', 'variation_theme', 'update_delete', 'part_number', 'product_description', 'catalog_number', 'bullet_point2', 'bullet_point3', 'bullet_point4', 'bullet_point5', 'generic_keywords', 'color_name', 'color_map', 'unit_count', 'unit Count Type', 'size_name', 'size Map', 'fulfillment_latency', 'specific_uses_keywords1', 'target_audience_keywords1', 'thesaurus_attribute_keywords', 'thesaurus_subject_keywords1']
    ]
    for row_index, row in enumerate(row_values, start=1):
        for col_index, value in enumerate(row, start=1):
            cell = ws.cell(row=row_index, column=col_index, value=value)
            cell.fill = fill
            cell.font = font
    wb.save(file_path_result)

    def run():
        list_url = url_input.get("1.0", "end").split("\n")
        for url in list_url:
            if url != "":
                log_frame.configure(state="normal")
                log_frame.insert("end", f"Start crawling {url}\n")
                log_frame.configure(state="disabled")
                crawl_product(url)
                log_frame.configure(state="normal")
                log_frame.insert("end", f"Finish crawling {url}\n")
                log_frame.configure(state="disabled")
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Crawling success\n")
        log_frame.configure(state="disabled")
    threading.Thread(target=run).start()
    

input_frame = customtkinter.CTkFrame(app, width=600, height=200)
input_frame.grid(row=0, column=0)
button_frame = customtkinter.CTkFrame(input_frame, width=270, height=200)
button_frame.grid(row=0, column=0, padx=(10, 0), pady=10)
start_button = customtkinter.CTkButton(button_frame, text="Start", command=start, width=270, height=130)
start_button.grid(row=0, column=0, pady=(0,10))
prefix_input = customtkinter.CTkEntry(button_frame, width=270, height=50, placeholder_text="Nhập prefix")
prefix_input.grid(row=1, column=0, pady=(10,0))
url_input = customtkinter.CTkTextbox(input_frame, width=300, height=200)
url_input.grid(row=0, column=1, padx=(5, 10), pady=10)

log_frame = customtkinter.CTkTextbox(app, width=600, height=200)
log_frame.grid(row=1, column=0)
log_frame.insert("end", f"#Log {datetime.datetime.now().strftime("%H:%M:%S - %d:%m:%Y")} - Lưu ý không mở file kết quả lúc đang crawl\n")
log_frame.configure(state="disabled")

app.mainloop()
