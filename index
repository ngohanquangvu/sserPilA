app = customtkinter.CTk()
app.title("Aliexpress Crawler")
app.geometry("600x400")

def get_des(url):
    html = requests.get(url).text
    soup = bs4.BeautifulSoup(html, 'html.parser')
    p_tags = soup.find_all('p')
    p_texts = ''.join([unicodedata.normalize("NFKD", tag.get_text()) for tag in p_tags])
    img_tags = soup.find_all('img')
    img_srcs = [tag.get('src') for tag in img_tags]
    return p_texts, img_srcs

def extract_between(text, sub1, sub2):
    return [t.split(sub2)[0] for t in text.split(sub1)[1:]]

logging.getLogger('seleniumwire').setLevel(logging.CRITICAL)
logging.getLogger('selenium').setLevel(logging.CRITICAL)
def get_chrome_pids():
    chrome_pids = []
    result = os.popen('tasklist /FI "IMAGENAME eq chrome.exe"').read()
    for line in result.splitlines():
        if 'chrome.exe' in line:
            parts = line.split()
            pid = int(parts[1])
            chrome_pids.append(pid)
    return chrome_pids

def kill_new_chrome_processes(old_pids):
    current_pids = get_chrome_pids()
    new_pids = set(current_pids) - set(old_pids)
    for pid in new_pids:
        try:
            os.system(f'taskkill /PID {pid} /F >nul 2>&1')
        except Exception as e:
            print(f"Error killing process {pid}: {e}")


def get_detail(url):
    global service
    old_pids = get_chrome_pids()
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument('--log-level=3')
    chrome_options.add_argument('--disable-logging')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--no-sandbox')

    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.get(url)
    for request in driver.requests:
        if "/h5/mtop.aliexpress.pdp.pc.query/1.0/" in request.url:
            if request.response:
                response_body = request.response.body
                if request.response.headers.get('Content-Encoding') == 'gzip':
                    buf = BytesIO(response_body)
                    f = gzip.GzipFile(fileobj=buf)
                    response_body = f.read().decode('utf-8')
                else:
                    response_body = response_body.decode('utf-8')
                if '"ret":["SUCCESS' in response_body:
                    kill_new_chrome_processes(old_pids)

                    driver.quit()
                    return response_body
    
    kill_new_chrome_processes(old_pids)
    driver.quit()
    return None

def crawl_product(url):
    global list_ck, file_path_result, font
    wb = openpyxl.load_workbook(file_path_result)
    ws = wb.active
    try:
        while True:
            try:
                detail = get_detail(url)
                if detail is not None:
                    break
                else:
                    log_frame.configure(state="normal")
                    log_frame.insert("end", f"Error: Vui lòng đổi ip, chạy lại sau 1p\n")
                    log_frame.configure(state="disabled")
                    time.sleep(60)
                    log_frame.configure(state="normal")
                    log_frame.insert("end", f"Retry: {url}\n")
                    log_frame.configure(state="disabled")
            except Exception as e:
                tb = e.__traceback__
                error_message = f" {url}| Exception: {e} | "
                while tb is not None:
                    filename = tb.tb_frame.f_code.co_filename
                    lineno = tb.tb_lineno
                    function_name = tb.tb_frame.f_code.co_name
                    error_message += f"File: {filename}, Line: {lineno}, in {function_name}\n"
                    tb = tb.tb_next
                with open("error_log.txt", 'a') as f:
                    f.write(error_message + '\n')
                pass
        while True:
            try:
                des = get_des(detail.split('pcDescUrl":"')[1].split('"')[0])[0]
                name = detail.split('"subject":"')[1].split('"')[0]
                break
            except Exception as e:
                pass
        next_row = ws.max_row + 1
        ws['A' + str(next_row)] = prefix_input.get()
        ws['A' + str(next_row)].font = font
        ws['B' + str(next_row)] = prefix_input.get()
        ws['B' + str(next_row)].font = font
        ws['C' + str(next_row)] = prefix_input.get()
        ws['C' + str(next_row)].font = font
        ws['D' + str(next_row)] = prefix_input.get()
        ws['D' + str(next_row)].font = font
        ws['J' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"
        ws['J' + str(next_row)].font = font
        ws['M' + str(next_row)] = 50
        ws['M' + str(next_row)].font = font
        ws['U' + str(next_row)] = "Parent"
        ws['U' + str(next_row)].font = font
        ws['X' + str(next_row)] = "Color"
        ws['X' + str(next_row)].font = font
        ws['H' + str(next_row)] = url
        ws['H' + str(next_row)].font = font
        ws['K' + str(next_row)] = name
        ws['K' + str(next_row)].font = font
        ws['AA' + str(next_row)] = des
        ws['AA' + str(next_row)].font = font
        ws['AJ' + str(next_row)] = "1"
        ws['AJ' + str(next_row)].font = font
        ws['AK' + str(next_row)] = "Count"
        ws['AK' + str(next_row)].font = font
        ws['AN' + str(next_row)] = "10"
        ws['AN' + str(next_row)].font = font
        wb.save(file_path_result)

        def extract_last_before_sub2(text, sub1, sub2):
            return text.split(sub2)[0].split(sub1)[-1]
        if detail.count('"skuPropertyValues":')==0:
            next_row = ws.max_row + 1
            ws['A' + str(next_row)] = prefix_input.get()
            ws['B' + str(next_row)] = prefix_input.get()
            ws['C' + str(next_row)] = prefix_input.get()
            ws['D' + str(next_row)] = prefix_input.get()
            ws['K' + str(next_row)] = name
            ws['AA' + str(next_row)] = des
            ws['H' + str(next_row)] = url
            ws['M' + str(next_row)] = 50
            ws['U' + str(next_row)] = "Child"
            ws['W' + str(next_row)] = "Variation"
            ws['X' + str(next_row)] = "Color"
            ws['AJ' + str(next_row)] = "1"
            ws['AK' + str(next_row)] = "Count"
            ws['AN' + str(next_row)] = "10"
            ws['J' + str(next_row)] = f"{prefix_input.get()}-1-{url.split('/')[-1].split('.html')[0]}"
            ws['V' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"
            a = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            ws['N' + str(next_row)] = a[0]
            img_url_index = 0
            for j in ["O", "P", "Q", "R", "S", "T"]:
                try:
                    ws[j + str(next_row)] = a[img_url_index]
                    img_url_index += 1
                except: break
            price = "9.99"
            ws['L' + str(next_row)] = str(price)
            ws['AI' + str(next_row)] = f"Color - 1"
            ws['AH' + str(next_row)] = f"Color - 1"
            wb.save(file_path_result)
            return
        elif detail.count('"skuPropertyValues":')==1:
            b = detail.split('"skuPropertyValues":[')[1]
            a = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            colors = extract_between(b,'"propertyValueDisplayName":"', '"')
            list_img = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            url_img = extract_between(b,'"skuPropertyImagePath":"', '"')
            dem_sku = 1
            for color in colors:
                next_row = ws.max_row + 1
                ws['A' + str(next_row)] = prefix_input.get()
                ws['B' + str(next_row)] = prefix_input.get()
                ws['C' + str(next_row)] = prefix_input.get()
                ws['D' + str(next_row)] = prefix_input.get()
                ws['K' + str(next_row)] = name
                ws['AA' + str(next_row)] = des
                ws['H' + str(next_row)] = url
                ws['M' + str(next_row)] = 50
                ws['U' + str(next_row)] = "Child"
                ws['W' + str(next_row)] = "Variation"
                ws['X' + str(next_row)] = "Color"
                ws['AJ' + str(next_row)] = "1"
                ws['AK' + str(next_row)] = "Count"
                ws['AN' + str(next_row)] = "10"
                ws['J' + str(next_row)] = f"{prefix_input.get()}-{dem_sku}-{url.split('/')[-1].split('.html')[0]}"
                ws['V' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"

                img_url_index = 0
                for j in ["O", "P", "Q", "R", "S", "T"]:
                    try:
                        ws[j + str(next_row)] = list_img[img_url_index]
                        img_url_index += 1
                    except: break    
                ws['N' + str(next_row)] = url_img[dem_sku-1]
                price = "9.99"
                ws['L' + str(next_row)] = str(price)
                ws['AI' + str(next_row)] = f"{color} - {dem_sku}"
                ws['AH' + str(next_row)] = f"{color} - {dem_sku}"
                dem_sku += 1
                wb.save(file_path_result)
        elif detail.count('"skuPropertyValues":')==2:
            b = detail.split('"skuPropertyValues":[')[1:]
            a = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            colors = extract_between(b[0],'"propertyValueDisplayName":"', '"')
            sizes = extract_between(b[1],'"propertyValueDisplayName":"', '"')
            url_img = extract_between(b[0],'"skuPropertyImagePath":"', '"')
            list_img = [i.replace('"','') for i in detail.split(f'"imagePathList":[')[1].split(']')[0].split(",")]
            for color in colors:
                dem_sku = 1
                for size in sizes:
                    next_row = ws.max_row + 1
                    ws['A' + str(next_row)] = prefix_input.get()
                    ws['B' + str(next_row)] = prefix_input.get()
                    ws['C' + str(next_row)] = prefix_input.get()
                    ws['D' + str(next_row)] = prefix_input.get()
                    ws['K' + str(next_row)] = name
                    ws['AA' + str(next_row)] = des
                    ws['H' + str(next_row)] = url
                    ws['M' + str(next_row)] = 50
                    ws['U' + str(next_row)] = "Child"
                    ws['W' + str(next_row)] = "Variation"
                    ws['X' + str(next_row)] = "Color"
                    ws['AJ' + str(next_row)] = "1"
                    ws['AK' + str(next_row)] = "Count"
                    ws['AN' + str(next_row)] = "10"
                    ws['J' + str(next_row)] = f"{prefix_input.get()}-{dem_sku}-{url.split('/')[-1].split('.html')[0]}"
                    ws['V' + str(next_row)] = f"{prefix_input.get()}-{url.split('/')[-1].split('.html')[0]}"

                    img_url_index = 0
                    for j in ["O", "P", "Q", "R", "S", "T"]:
                        try:
                            ws[j + str(next_row)] = list_img[img_url_index]
                            img_url_index += 1
                        except: break    
                    ws['N' + str(next_row)] = url_img[dem_sku-1]
                    price = "9.99"
                    ws['L' + str(next_row)] = str(price)
                    ws['AI' + str(next_row)] = f"{color} - {size} - {dem_sku}"
                    ws['AH' + str(next_row)] = f"{color} - {size} - {dem_sku}"
                    wb.save(file_path_result)
                dem_sku += 1
    except Exception as e:
        def save_error_to_file(error_message):
            with open("error_log.txt", 'a') as f:
                f.write(error_message + '\n')
        tb = e.__traceback__
        error_message = f" {url}| Exception: {e} | "
        while tb is not None:
            filename = tb.tb_frame.f_code.co_filename
            lineno = tb.tb_lineno
            function_name = tb.tb_frame.f_code.co_name
            error_message += f"File: {filename}, Line: {lineno}, in {function_name}\n"
            tb = tb.tb_next
        save_error_to_file(error_message)
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Error: {url}\n")
        log_frame.configure(state="disabled")

service = None
def check_service():
    global service
    if service is None:
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Driver is downloading, please wait...\n")
        log_frame.configure(state="disabled")
    try:
        service = Service(ChromeDriverManager().install())
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument('--log-level=3')
        chrome_options.add_argument('--disable-logging')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--no-sandbox')
        driver = webdriver.Chrome(service=service, options=chrome_options)
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Driver is available\n")
        log_frame.configure(state="disabled")
    except Exception as e:
        chrome_version = str(e).split("Current browser version is ")[1].split(" ")[0]
        try:
            service = Service(ChromeDriverManager(driver_version=chrome_version).install())
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument('--log-level=3')
            chrome_options.add_argument('--disable-logging')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--no-sandbox')
            driver = webdriver.Chrome(service=service, options=chrome_options)
            log_frame.configure(state="normal")
            log_frame.insert("end", f"Driver is available\n")
            log_frame.configure(state="disabled")
        except Exception as e:
            tb = e.__traceback__
            error_message = f"Exception: {e} | "
            while tb is not None:
                filename = tb.tb_frame.f_code.co_filename
                lineno = tb.tb_lineno
                function_name = tb.tb_frame.f_code.co_name
                error_message += f"File: {filename}, Line: {lineno}, in {function_name}\n"
                tb = tb.tb_next
            with open("error_log.txt", 'a') as f:
                f.write(error_message + '\n')
            log_frame.configure(state="normal")
            log_frame.insert("end", f"Error: Không tìm thấy driver phù hợp\n")
            log_frame.configure(state="disabled")
            service = None
def run_check_service():
    global service
    threading.Thread(target=check_service).start()

def open_folder(path):
    os.system(f'start {os.path.realpath(path)}')

def get_unique_filename(base_name, extension):
    counter = 1
    file_name = f"{base_name}{extension}"
    while os.path.exists(file_name):
        file_name = f"{base_name}({counter}){extension}"
        counter += 1
    return file_name

def start():
    global file_path_result, font, fill, service
    log_frame.configure(state="normal")
    log_frame.insert("end", f"Start running...\n")
    log_frame.configure(state="disabled")
    if service is None:
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Please check driver\n")
        log_frame.configure(state="disabled")
        return

    file_path_result =  f'{prefix_input.get()}-Cao'
    file_path_result = get_unique_filename(file_path_result, ".xlsx")
    if not os.path.exists(file_path_result):
        wb = Workbook()
        wb.save(file_path_result)
    wb = openpyxl.load_workbook(file_path_result)
    ws = wb.active
    fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
    font = Font(color="FF0000")
    row_values = [
        ['TemplateType=fptcustom', 'Version=2021.0709', 'TemplateSignature=TVVMVElUT09M', 'settings=contentLanguageTag=en_US&feedType=610841&headerLanguageTag=en_US&primaryMarketplaceId=amzn1.mp.o.ATVPDKIKX0DER&templateIdentifier=c8bf49ba-63dc-4a50-9056-059404a3a2aa&timestamp=2021-07-09T17%3A36%3A18.873Z', 'Use ENGLISH to fill this template.The top 3 rows are for Amazon.com use only. Do not modify or delete the top 3 rows.', 'a1', 'a0', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'Images', 'a9', 'a10', 'a11', 'a12', 'a13', 'Variation', 'a14', 'a15', 'a16', 'Basic', 'a17', 'a18', 'Discovery', 'a19', 'a20', 'a21', 'a22', 'a23', 'a24', 'a25', 'a26', 'a27', 'a28', 'a29', 'a30', 'a31', 'a32', 'a33', 'a34'],
        ['Product Type', 'Item Type Keyword', 'Brand Name', 'Manufacturer', 'Product ID', 'Product ID Type', 'Order Ali', 'Link SP', 'Key Product Features', 'Seller SKU', 'Product Name', 'Standard Price', 'Quantity', 'Main Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Other Image URL', 'Parentage', 'Parent SKU', 'Relationship Type', 'Variation Theme', 'Update Delete', 'Manufacturer Part Number', 'Product Description', 'Catalog Number', 'Key Product Features', 'Key Product Features', 'Key Product Features', 'Key Product Features', 'Search Terms', 'Color', 'Color Map', 'Unit Count', 'Unit Count Type', 'Size', 'Size Map', 'Handling Time', 'Intended Use', 'Target Audience', 'Other Attributes', 'Subject Matter'],
        ['feed_product_type', 'item_type', 'brand_name', 'manufacturer', 'external_product_id', 'external_product_id_type', '', '', 'bullet_point1', 'item_sku', 'item_name', 'standard_price', 'quantity', 'main_image_url', 'other_image_url1', 'other_image_url2', 'other_image_url3', 'other_image_url4', 'other_image_url5', 'other_image_url6', 'parent_child', 'parent_sku', 'relationship_type', 'variation_theme', 'update_delete', 'part_number', 'product_description', 'catalog_number', 'bullet_point2', 'bullet_point3', 'bullet_point4', 'bullet_point5', 'generic_keywords', 'color_name', 'color_map', 'unit_count', 'unit Count Type', 'size_name', 'size Map', 'fulfillment_latency', 'specific_uses_keywords1', 'target_audience_keywords1', 'thesaurus_attribute_keywords', 'thesaurus_subject_keywords1']
    ]
    for row_index, row in enumerate(row_values, start=1):
        for col_index, value in enumerate(row, start=1):
            cell = ws.cell(row=row_index, column=col_index, value=value)
            cell.fill = fill
            cell.font = font
    wb.save(file_path_result)

    def run():
        list_url = url_input.get("1.0", "end").split("\n")
        for url in list_url:
            if url != "":
                log_frame.configure(state="normal")
                log_frame.insert("end", f"Start crawling {url}\n")
                log_frame.configure(state="disabled")
                crawl_product(url)
                log_frame.configure(state="normal")
                log_frame.insert("end", f"Finish crawling {url}\n")
                log_frame.configure(state="disabled")
        log_frame.configure(state="normal")
        log_frame.insert("end", f"Crawling success\n")
        log_frame.configure(state="disabled")
        open_folder(os.getcwd())    
    threading.Thread(target=run).start()
    

input_frame = customtkinter.CTkFrame(app, width=600, height=200)
input_frame.grid(row=0, column=0)
button_frame = customtkinter.CTkFrame(input_frame, width=270, height=200)
button_frame.grid(row=0, column=0, padx=(10, 0), pady=10)
start_button = customtkinter.CTkButton(button_frame, text="Start", command=start, width=270, height=55)
start_button.grid(row=0, column=0, pady=(0,0))
service_button = customtkinter.CTkButton(button_frame, text="Check driver", command=run_check_service, width=270, height=55)
service_button.grid(row=1, column=0, pady=(10,0))
prefix_input = customtkinter.CTkEntry(button_frame, width=270, height=50, placeholder_text="Nhập prefix")
prefix_input.grid(row=2, column=0, pady=(10,0))
url_input = customtkinter.CTkTextbox(input_frame, width=300, height=200)
url_input.grid(row=0, column=1, padx=(5, 10), pady=10)

log_frame = customtkinter.CTkTextbox(app, width=600, height=200)
log_frame.grid(row=1, column=0)
log_frame.insert("end", f"#Log {datetime.datetime.now().strftime("%H:%M:%S - %d:%m:%Y")} - Lưu ý không mở file kết quả lúc đang crawl\n")
log_frame.configure(state="disabled")

app.mainloop()
